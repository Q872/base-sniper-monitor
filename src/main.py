#!/usr/bin/env python3
"""
Baseé“¾æ™ºèƒ½ç‹™å‡»ç›‘æ§ç³»ç»Ÿ - ä¸»ç¨‹åº
äº”çº§é£æ§å¢å¼ºç‰ˆ - é›†æˆDexScreener APIå’Œä»·æ ¼è¿½è¸ª
"""

import asyncio
import aiohttp
import yaml
import os
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional

class TokenDataManager:
    def __init__(self, data_file: str = "data/token_history.json"):
        self.data_file = data_file
        self._ensure_data_file()
    
    def _ensure_data_file(self):
        """ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨"""
        os.makedirs(os.path.dirname(self.data_file), exist_ok=True)
        if not os.path.exists(self.data_file):
            with open(self.data_file, 'w') as f:
                json.dump({"tokens": {}, "statistics": {}}, f, indent=2)
    
    def load_data(self) -> Dict:
        """åŠ è½½å†å²æ•°æ®"""
        try:
            with open(self.data_file, 'r') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
            return {"tokens": {}, "statistics": {}}
    
    def save_data(self, data: Dict):
        """ä¿å­˜æ•°æ®"""
        try:
            with open(self.data_file, 'w') as f:
                json.dump(data, f, indent=2)
        except Exception as e:
            print(f"âŒ ä¿å­˜æ•°æ®å¤±è´¥: {e}")
    
    def record_token_price(self, token_address: str, symbol: str, price: float, liquidity: float):
        """è®°å½•ä»£å¸ä»·æ ¼"""
        data = self.load_data()
        current_time = datetime.now().isoformat()
        
        if token_address not in data["tokens"]:
            data["tokens"][token_address] = {
                "symbol": symbol,
                "first_seen": current_time,
                "price_history": [],
                "highest_price": price,
                "lowest_price": price,
                "initial_price": price,
                "initial_liquidity": liquidity
            }
        
        token_data = data["tokens"][token_address]
        token_data["price_history"].append({
            "timestamp": current_time,
            "price": price,
            "liquidity": liquidity
        })
        
        # ä¿ç•™æœ€è¿‘100æ¡è®°å½•
        if len(token_data["price_history"]) > 100:
            token_data["price_history"] = token_data["price_history"][-100:]
        
        # æ›´æ–°æœ€é«˜/æœ€ä½ä»·æ ¼
        token_data["highest_price"] = max(token_data["highest_price"], price)
        token_data["lowest_price"] = min(token_data["lowest_price"], price)
        token_data["current_price"] = price
        token_data["last_updated"] = current_time
        
        self.save_data(data)
        return token_data
    
    def calculate_returns(self, token_address: str) -> Dict:
        """è®¡ç®—æ”¶ç›Šç‡"""
        data = self.load_data()
        if token_address not in data["tokens"]:
            return {}
        
        token_data = data["tokens"][token_address]
        initial_price = token_data["initial_price"]
        current_price = token_data["current_price"]
        
        if initial_price == 0:
            return {}
        
        total_return = ((current_price - initial_price) / initial_price) * 100
        
        # è®¡ç®—24å°æ—¶æ”¶ç›Šç‡ï¼ˆå¦‚æœæœ‰è¶³å¤Ÿæ•°æ®ï¼‰
        twenty_four_hours_ago = datetime.now() - timedelta(hours=24)
        price_24h_ago = initial_price
        
        for price_point in reversed(token_data["price_history"]):
            price_time = datetime.fromisoformat(price_point["timestamp"])
            if price_time <= twenty_four_hours_ago:
                price_24h_ago = price_point["price"]
                break
        
        return_24h = ((current_price - price_24h_ago) / price_24h_ago) * 100 if price_24h_ago > 0 else 0
        
        return {
            "total_return": round(total_return, 2),
            "return_24h": round(return_24h, 2),
            "initial_price": initial_price,
            "current_price": current_price,
            "price_change": current_price - initial_price,
            "highest_return": round(((token_data["highest_price"] - initial_price) / initial_price) * 100, 2),
            "current_liquidity": token_data["price_history"][-1]["liquidity"] if token_data["price_history"] else 0
        }
    
    def get_top_performers(self, limit: int = 10) -> List[Dict]:
        """è·å–è¡¨ç°æœ€å¥½çš„ä»£å¸"""
        data = self.load_data()
        performers = []
        
        for address, token_data in data["tokens"].items():
            returns = self.calculate_returns(address)
            if returns and returns.get("total_return") is not None:
                performers.append({
                    "address": address,
                    "symbol": token_data["symbol"],
                    **returns
                })
        
        # æŒ‰æ€»æ”¶ç›Šç‡æ’åº
        performers.sort(key=lambda x: x.get("total_return", 0), reverse=True)
        return performers[:limit]
    
    def get_recent_tokens(self, hours: int = 24) -> List[Dict]:
        """è·å–æœ€è¿‘å‘ç°çš„ä»£å¸"""
        data = self.load_data()
        recent_tokens = []
        cutoff_time = datetime.now() - timedelta(hours=hours)
        
        for address, token_data in data["tokens"].items():
            first_seen = datetime.fromisoformat(token_data["first_seen"])
            if first_seen >= cutoff_time:
                returns = self.calculate_returns(address)
                recent_tokens.append({
                    "address": address,
                    "symbol": token_data["symbol"],
                    "first_seen": token_data["first_seen"],
                    **returns
                })
        
        # æŒ‰å‘ç°æ—¶é—´æ’åº
        recent_tokens.sort(key=lambda x: x["first_seen"], reverse=True)
        return recent_tokens

class DexScreenerAPI:
    def __init__(self):
        self.base_url = "https://api.dexscreener.com/latest/dex"
    
    async def search_tokens(self, query: str = "base", limit: int = 25):
        """æœç´¢Baseé“¾ä¸Šçš„ä»£å¸"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    f"{self.base_url}/search/?q={query}&limit={limit}",
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    data = await response.json()
                    return data.get("pairs", [])
        except Exception as e:
            print(f"DexScreener API æœç´¢å¤±è´¥: {e}")
            return []

# åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
data_manager = TokenDataManager()

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    try:
        with open('config.yaml', 'r', encoding='utf-8') as file:
            config = yaml.safe_load(file)
            print("âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
            return config
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        return {}

def load_risk_addresses():
    """åŠ è½½é£é™©åœ°å€æ•°æ®åº“"""
    try:
        with open('data/risk_addresses.txt', 'r') as f:
            addresses = set(line.strip().lower() for line in f if line.strip())
            print(f"âœ… é£é™©åœ°å€æ•°æ®åº“åŠ è½½æˆåŠŸ: {len(addresses)} ä¸ªåœ°å€")
            return addresses
    except FileNotFoundError:
        print("âš ï¸ é£é™©åœ°å€æ•°æ®åº“æœªæ‰¾åˆ°ï¼Œå°†ä½¿ç”¨ç©ºæ•°æ®åº“")
        return set()

async def analyze_deployer_interactions(deployer_address):
    """åˆ†æéƒ¨ç½²è€…äº¤äº’å†å²"""
    print(f"ğŸ” åˆ†æéƒ¨ç½²è€…äº¤äº’: {deployer_address}")
    await asyncio.sleep(0.5)  # æ¨¡æ‹ŸAPIè°ƒç”¨
    
    # è¿™é‡Œå¯ä»¥é›†æˆå®é™…çš„é“¾ä¸Šåˆ†æAPI
    return {
        "risk_interactions": 0, 
        "details": [],
        "deployer_risk_score": 30
    }

async def analyze_top_holders(token_address):
    """åˆ†æå‰10å¤§æˆ·é£é™©"""
    print(f"ğŸ‘¥ åˆ†æå¤§æˆ·é£é™©: {token_address}")
    await asyncio.sleep(0.5)  # æ¨¡æ‹ŸAPIè°ƒç”¨
    
    return {
        "risk_holders": 0, 
        "details": [],
        "holder_concentration": 25
    }

async def calculate_score(token_data, deployer_analysis, holder_analysis):
    """è®¡ç®—ç»¼åˆè¯„åˆ†"""
    print("ğŸ“Š è®¡ç®—ç»¼åˆè¯„åˆ†...")
    
    score = 50  # åŸºç¡€åˆ†
    
    # 1. æµåŠ¨æ€§è¯„åˆ† (25åˆ†)
    liquidity = token_data.get('liquidity', {}).get('usd', 0)
    if liquidity > 20000:
        score += 25
    elif liquidity > 10000:
        score += 20
    elif liquidity > 5000:
        score += 15
    elif liquidity > 1000:
        score += 5
    
    # 2. äº¤æ˜“é‡è¯„åˆ† (15åˆ†)
    volume = token_data.get('volume', {}).get('h24', 0)
    if volume > 50000:
        score += 15
    elif volume > 20000:
        score += 10
    elif volume > 5000:
        score += 5
    
    # 3. éƒ¨ç½²è€…é£é™©è¯„åˆ† (20åˆ†)
    deployer_score = deployer_analysis.get('deployer_risk_score', 50)
    score += (deployer_score - 50) * 0.4  # è½¬æ¢ä¸º20åˆ†åˆ¶
    
    # 4. å¤§æˆ·é›†ä¸­åº¦è¯„åˆ† (15åˆ†)
    holder_score = 50 - holder_analysis.get('holder_concentration', 0)
    score += holder_score * 0.3  # è½¬æ¢ä¸º15åˆ†åˆ¶
    
    # 5. ä»£å¸å¹´é¾„åŠ åˆ† (10åˆ†)
    age_minutes = token_data.get('age_minutes', 1440)  # é»˜è®¤1å¤©
    if age_minutes <= 30:  # 30åˆ†é’Ÿå†…çš„æ–°å¸
        score += 10
    elif age_minutes <= 120:  # 2å°æ—¶å†…çš„å¸
        score += 5
    
    # 6. ä»·æ ¼ç¨³å®šæ€§ (10åˆ†)
    price_change = abs(token_data.get('priceChange', {}).get('h24', 0))
    if price_change < 50:  # 24å°æ—¶æ¶¨è·Œå¹…å°äº50%
        score += 10
    elif price_change < 100:
        score += 5
    
    return min(max(score, 0), 100)

async def send_telegram_alert(token_data, score):
    """å‘é€Telegramè­¦æŠ¥ - å¢å¼ºç‰ˆï¼ŒåŒ…å«æ”¶ç›Šç‡ä¿¡æ¯"""
    bot_token = os.getenv('TELEGRAM_BOT_TOKEN')
    chat_id = os.getenv('TELEGRAM_CHAT_ID')
    
    if not bot_token or not chat_id:
        print("âš ï¸ Telegramé…ç½®ç¼ºå¤±ï¼Œè·³è¿‡å‘é€")
        return
    
    # æ·»åŠ æ”¶ç›Šç‡ä¿¡æ¯
    returns_info = ""
    if token_data.get("returns"):
        returns = token_data["returns"]
        returns_info = f"ğŸ“ˆ å½“å‰æ”¶ç›Šç‡: {returns.get('total_return', 0):.2f}%\n"
    
    message = f"""ğŸš¨ *BASEé“¾ä¼˜è´¨ä»£å¸è­¦æŠ¥* ğŸš¨

ğŸ’° *{token_data['name']} ({token_data['symbol']})*
ğŸ† ç»¼åˆè¯„åˆ†: {score}/100
{returns_info}ğŸ’§ æµåŠ¨æ€§: ${token_data['liquidity']:,.0f}
ğŸ“Š 24häº¤æ˜“é‡: ${token_data['volume']:,.0f}
â° ä»£å¸å¹´é¾„: {token_data['age_minutes']}åˆ†é’Ÿ
ğŸ”º 24hæ¶¨è·Œ: {token_data.get('price_change_24h', 0):.1f}%

ğŸ“‹ åˆçº¦åœ°å€: `{token_data['address']}`
ğŸ”— [DexScreeneråˆ†æ]({token_data['url']})

âš ï¸ æŠ•èµ„æœ‰é£é™©ï¼Œè¯·è‡ªè¡Œç ”ç©¶ï¼"""
    
    try:
        async with aiohttp.ClientSession() as session:
            payload = {
                'chat_id': chat_id,
                'text': message,
                'parse_mode': 'Markdown',
                'disable_web_page_preview': True
            }
            async with session.post(
                f'https://api.telegram.org/bot{bot_token}/sendMessage',
                json=payload
            ) as response:
                if response.status == 200:
                    print(f"âœ… Telegramè­¦æŠ¥å‘é€æˆåŠŸ: {token_data['symbol']}")
                else:
                    print(f"âŒ Telegramå‘é€å¤±è´¥: {await response.text()}")
    except Exception as e:
        print(f"âŒ Telegramå‘é€é”™è¯¯: {e}")

async def send_performance_report(top_performers: List, recent_tokens: List):
    """å‘é€æ€§èƒ½æŠ¥å‘Šåˆ°Telegram"""
    bot_token = os.getenv('TELEGRAM_BOT_TOKEN')
    chat_id = os.getenv('TELEGRAM_CHAT_ID')
    
    if not bot_token or not chat_id:
        return
    
    message = "ğŸ“Š *Baseé“¾ä»£å¸è¡¨ç°æŠ¥å‘Š*\n\n"
    
    message += "ğŸ† *é¡¶çº§è¡¨ç°è€…:*\n"
    for i, token in enumerate(top_performers, 1):
        message += f"{i}. {token['symbol']}: {token['total_return']}%\n"
    
    message += f"\nğŸ†• *24å°æ—¶æ–°å¸ ({len(recent_tokens)}ä¸ª)*\n"
    for token in recent_tokens[:3]:
        return_text = f"{token.get('total_return', 'N/A')}%" if token.get('total_return') else "æ–°å¸"
        message += f"â€¢ {token['symbol']}: {return_text}\n"
    
    message += f"\nâ° æŠ¥å‘Šæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}"
    
    try:
        async with aiohttp.ClientSession() as session:
            payload = {
                'chat_id': chat_id,
                'text': message,
                'parse_mode': 'Markdown'
            }
            async with session.post(
                f'https://api.telegram.org/bot{bot_token}/sendMessage',
                json=payload
            ) as response:
                if response.status == 200:
                    print("âœ… æ€§èƒ½æŠ¥å‘Šå‘é€æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ€§èƒ½æŠ¥å‘Šå‘é€å¤±è´¥: {e}")

async def generate_performance_report():
    """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
    print("\n" + "="*50)
    print("ğŸ“ˆ ä»£å¸è¡¨ç°æŠ¥å‘Š")
    print("="*50)
    
    # è·å–é¡¶çº§è¡¨ç°è€…
    top_performers = data_manager.get_top_performers(5)
    recent_tokens = data_manager.get_recent_tokens(24)
    
    print(f"ğŸ† é¡¶çº§è¡¨ç°è€… (å‰5):")
    for i, token in enumerate(top_performers, 1):
        print(f"   {i}. {token['symbol']}: {token['total_return']}%")
    
    print(f"\nğŸ†• æœ€è¿‘24å°æ—¶å‘ç°çš„ä»£å¸ ({len(recent_tokens)}ä¸ª):")
    for token in recent_tokens[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"   â€¢ {token['symbol']}: {token.get('total_return', 'N/A')}%")
    
    # å‘é€TelegramæŠ¥å‘Š
    await send_performance_report(top_performers, recent_tokens)

async def analyze_token(token_data):
    """åˆ†æå•ä¸ªä»£å¸"""
    print(f"\nğŸª™ åˆ†æä»£å¸: {token_data['symbol']} - {token_data['name']}")
    print(f"   ğŸ’§ æµåŠ¨æ€§: ${token_data['liquidity']:,}")
    print(f"   ğŸ“ˆ 24häº¤æ˜“é‡: ${token_data['volume']:,}")
    print(f"   â° ä»£å¸å¹´é¾„: {token_data['age_minutes']}åˆ†é’Ÿ")
    
    # è®°å½•ä»£å¸ä»·æ ¼
    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦è·å–å®é™…ä»·æ ¼ï¼ŒDexScreener APIè¿”å›çš„ä»·æ ¼å­—æ®µå¯èƒ½æ˜¯priceUsd
    price = token_data.get('priceUsd', 0) or 0
    data_manager.record_token_price(
        token_data["address"],
        token_data["symbol"],
        price,
        token_data["liquidity"]
    )
    
    # è®¡ç®—æ”¶ç›Šç‡
    returns = data_manager.calculate_returns(token_data["address"])
    if returns:
        print(f"   ğŸ“Š å½“å‰æ”¶ç›Šç‡: {returns.get('total_return', 0):.2f}%")
    
    # åŸæœ‰çš„åˆ†æé€»è¾‘ä¿æŒä¸å˜
    deployer_task = analyze_deployer_interactions(token_data["deployer"])
    holder_task = analyze_top_holders(token_data["address"])
    
    deployer_analysis, holder_analysis = await asyncio.gather(deployer_task, holder_task)
    
    # è®¡ç®—ç»¼åˆè¯„åˆ†
    score = await calculate_score(token_data, deployer_analysis, holder_analysis)
    
    print(f"   âœ… åˆ†æå®Œæˆ - è¯„åˆ†: {score}/100")
    
    # æ ¹æ®è¯„åˆ†å†³å®šæ˜¯å¦æ¨é€
    config = load_config()
    min_score = config.get('risk_thresholds', {}).get('min_score', 60)
    good_score = config.get('risk_thresholds', {}).get('good_score', 75)
    
    quality_tokens = 0
    
    if score >= 50:
        print("   ğŸŸ¢ ä¼˜è´¨é¡¹ç›® - å‘é€è­¦æŠ¥")
        # åœ¨è­¦æŠ¥ä¸­æ·»åŠ æ”¶ç›Šç‡ä¿¡æ¯
        if returns:
            token_data["returns"] = returns
        await send_telegram_alert(token_data, score)
        quality_tokens = 1
    elif score >= min_score:
        print("   ğŸŸ¡ ä¸­ç­‰é£é™© - éœ€è¦äººå·¥å®¡æ ¸")
    else:
        print("   ğŸ”´ é«˜é£é™© - é™é»˜ä¸¢å¼ƒ")
    
    return {"quality_tokens": quality_tokens}

async def monitor_new_tokens():
    """ç›‘æ§æ–°å¸ç§ - å®Œæ•´åŠŸèƒ½ç‰ˆï¼Œåˆ†ææ‰€æœ‰è·å–åˆ°çš„ä»£å¸"""
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"ğŸš€ [{current_time}] å¼€å§‹ç›‘æ§Baseé“¾æ–°å¸ç§...")
    
    # ä½¿ç”¨DexScreener APIè·å–æ•°æ®
    dexscreener = DexScreenerAPI()
    pairs = await dexscreener.search_tokens('base', 25)
    
    if not pairs:
        print("âŒ æœªä»DexScreenerè·å–åˆ°æ•°æ®")
        return False
    
    # è¿‡æ»¤Baseé“¾ä»£å¸
    base_pairs = [pair for pair in pairs if pair.get('chainId') == 'base']
    print(f"ğŸ“Š ä»DexScreenerè·å–åˆ° {len(base_pairs)} ä¸ªBaseé“¾ä»£å¸")
    
    # æŒ‰åˆ›å»ºæ—¶é—´æ’åº
    base_pairs.sort(key=lambda x: x.get('pairCreatedAt', 0), reverse=True)
    
    found_quality_tokens = 0
    
    # åˆ†ææ‰€æœ‰Baseé“¾ä»£å¸ï¼ˆä¸é™åˆ¶æ•°é‡ï¼‰
    analysis_tasks = []
    for pair in base_pairs:  # æ²¡æœ‰æ•°é‡é™åˆ¶ï¼Œåˆ†ææ‰€æœ‰ä»£å¸
        token_data = {
            "address": pair.get('baseToken', {}).get('address'),
            "name": pair.get('baseToken', {}).get('name', 'Unknown'),
            "symbol": pair.get('baseToken', {}).get('symbol', 'Unknown'),
            "deployer": pair.get('baseToken', {}).get('address'),
            "liquidity": pair.get('liquidity', {}).get('usd', 0),
            "volume": pair.get('volume', {}).get('h24', 0),
            "priceChange": pair.get('priceChange', {}),
            "price_change_24h": pair.get('priceChange', {}).get('h24', 0),
            "priceUsd": pair.get('priceUsd', 0),
            "pairAddress": pair.get('pairAddress'),
            "url": pair.get('url', ''),
            "age_minutes": int((datetime.now().timestamp() * 1000 - pair.get('pairCreatedAt', 0)) / 60000)
        }
        
        if not token_data["address"]:
            continue
            
        # åˆ›å»ºåˆ†æä»»åŠ¡
        task = analyze_token(token_data)
        analysis_tasks.append(task)
    
    # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰åˆ†æä»»åŠ¡
    if analysis_tasks:
        results = await asyncio.gather(*analysis_tasks, return_exceptions=True)
        
        for result in results:
            if isinstance(result, Exception):
                print(f"âŒ åˆ†æä»»åŠ¡å‡ºé”™: {result}")
                continue
                
            if result and result.get('quality_tokens', 0) > 0:
                found_quality_tokens += result['quality_tokens']
    
    print(f"ğŸ¯ æœ¬æ¬¡ç›‘æ§å‘ç° {found_quality_tokens} ä¸ªä¼˜è´¨é¡¹ç›®")
    return True

async def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("=== Baseé“¾æ™ºèƒ½ç‹™å‡»ç›‘æ§ç³»ç»Ÿå¯åŠ¨ ===")
    print("=== å®Œæ•´åŠŸèƒ½ç‰ˆ + ä»·æ ¼è¿½è¸ª ===")
    print("=" * 50)

        print("=" * 50)
    print("=== Baseé“¾æ™ºèƒ½ç‹™å‡»ç›‘æ§ç³»ç»Ÿå¯åŠ¨ ===")
    print("=== å®Œæ•´åŠŸèƒ½ç‰ˆ + ä»·æ ¼è¿½è¸ª ===")
    print("=" * 50)

    # ğŸ”§ æ·»åŠ åœ¨è¿™é‡Œ - å¼ºåˆ¶æµ‹è¯• Telegram è¿æ¥
    print("ğŸ”§ å¼ºåˆ¶æµ‹è¯• Telegram è¿æ¥...")
    test_token_data = {
        "name": "æµ‹è¯•ä»£å¸",
        "symbol": "TEST",
        "liquidity": 10000,
        "volume": 50000,
        "age_minutes": 5,
        "price_change_24h": 10.5,
        "address": "0xTEST123456789",
        "url": "https://dexscreener.com/base/0xTEST"
    }
    await send_telegram_alert(test_token_data, 80)
    print("âœ… å¼ºåˆ¶æµ‹è¯•æ¶ˆæ¯å·²å‘é€")

    start_time = datetime.now()
    
    # åŠ è½½é…ç½®å’Œé£é™©æ•°æ®åº“
    risk_addresses = load_risk_addresses()
    config = load_config()
    
    print(f"ğŸ“ é…ç½®åŠ è½½: {len(risk_addresses)} ä¸ªé£é™©åœ°å€")
    
    # æ‰§è¡Œç›‘æ§
    try:
        await monitor_new_tokens()
        print("âœ… ç›‘æ§ä»»åŠ¡æ‰§è¡Œå®Œæˆ")
        
        # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
        await generate_performance_report()
        
    except Exception as e:
        print(f"âŒ ç›‘æ§ä»»åŠ¡å‡ºé”™: {e}")
    
    duration = (datetime.now() - start_time).total_seconds()
    print(f"â±ï¸ æ€»æ‰§è¡Œæ—¶é—´: {duration:.1f}ç§’")
    
    print("=" * 50)
    print("=== ç³»ç»Ÿè¿è¡Œå®Œæˆï¼Œç­‰å¾…ä¸‹æ¬¡è§¦å‘ ===")
    print("=" * 50)

if __name__ == "__main__":
    asyncio.run(main())
